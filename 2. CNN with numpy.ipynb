{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network\n",
    "\n",
    "### index\n",
    "\n",
    "- filter\n",
    "- padding\n",
    "- stride\n",
    "- activation\n",
    "- FC layer\n",
    "\n",
    "### motivation\n",
    "\n",
    "CNN의 내부동작원리의 이해를 돕기 위한 자료\n",
    "\n",
    "### data\n",
    "\n",
    "MNIST dataset\n",
    "\n",
    "### reference \n",
    "- cs231n convolution neural network\n",
    "- https://github.com/raphey/numpy-cnn/blob/master/nn_util.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset download and prepare dataset\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def rough_print(num_arr): # 글자모양 출력\n",
    "    \"\"\"\n",
    "    Simple way to print a 784-length number array, outputting '.' for every cell == 0 and 'X' for cells > 0\n",
    "    \"\"\"\n",
    "    new_shape = num_arr.reshape((28, 28))\n",
    "    for row in new_shape: # len(row)==28\n",
    "        row_str = \"\"\n",
    "        for entry in row: # row의 elm\n",
    "            if entry > 0:\n",
    "                row_str += 'X'\n",
    "            else:\n",
    "                row_str += '.'\n",
    "        print(row_str)\n",
    "\n",
    "\n",
    "def shuffle_data(data_obj, random_seed=0):\n",
    "    \"\"\"\n",
    "    Given a data_obj with ['data'] and ['target] entries, shuffles them and returns them as separate arrays.\n",
    "    \"\"\"\n",
    "    d = data_obj['data']\n",
    "    t = data_obj['target'].reshape(-1, 1)\n",
    "\n",
    "    return shuffle(d, t, random_state=random_seed)\n",
    "\n",
    "\n",
    "def import_and_prepare_mnist_data(valid_portion=0.1, test_portion=0.1, flat=True):\n",
    "    \"\"\"\n",
    "    Imports mnist data, shuffles it, and splits it into training, validation, and testing sets.\n",
    "\n",
    "    If flat parameter is set to False, each image will be reshaped from (784) to (28 x 28 x 1), for convolution.\n",
    "\n",
    "    training, validation, and testing are dicts with three keys each:\n",
    "      'x': the image data\n",
    "      'y_': the one-hot encoded labels\n",
    "      'y_as_int': the labels as integers, for quick accuracy checking\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    data_size = len(mnist['data'])\n",
    "\n",
    "    img_data, int_targets = shuffle_data(mnist)\n",
    "\n",
    "    if not flat:\n",
    "        img_data = img_data.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    scaled_data = img_data / 255.0\n",
    "\n",
    "    int_targets = int_targets.astype(int)\n",
    "\n",
    "    one_hots = one_hot_encode(int_targets)\n",
    "\n",
    "    # Cutoff indices between training/validation and validation/testing\n",
    "    validation_start = int((1.0 - valid_portion - test_portion) * data_size)\n",
    "    testing_start = int((1.0 - test_portion) * data_size)\n",
    "\n",
    "    train = {'x': scaled_data[:validation_start],\n",
    "             'y_': one_hots[:validation_start],\n",
    "             'y_as_int': int_targets[:validation_start]}\n",
    "\n",
    "    valid = {'x': scaled_data[validation_start: testing_start],\n",
    "             'y_': one_hots[validation_start: testing_start],\n",
    "             'y_as_int': int_targets[validation_start: testing_start]}\n",
    "\n",
    "    test = {'x': scaled_data[testing_start:],\n",
    "            'y_': one_hots[testing_start:],\n",
    "            'y_as_int': int_targets[testing_start:]}\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "\n",
    "def initialize_weight_array(l, w, stddev=None, relu=False, sigma_cutoff=2.0):\n",
    "    \"\"\"\n",
    "    Initializes a weight array with l rows and w columns.\n",
    "    If stddev is not specified, default initialization is designed to create a variance of 1.0,\n",
    "    meaning stddev is sqrt(1 / N_in). If the weight array is going to be used with relu\n",
    "    activation, the default stddev will be sqrt(2 / N_in), since presumably half the neurons\n",
    "    won't fire.\n",
    "    sigma_cutoff determines the max number of stddevs away from 0 an initialized value can be.\n",
    "    \"\"\"\n",
    "    if stddev is None:\n",
    "        if relu:\n",
    "            stddev = (2.0 / l) ** 0.5\n",
    "        else:\n",
    "            stddev = (1.0 / l) ** 0.5\n",
    "\n",
    "    weights = []\n",
    "    while len(weights) < l * w:\n",
    "        new_rand_val = np.random.randn() * stddev\n",
    "        if abs(new_rand_val) < sigma_cutoff * stddev:\n",
    "            weights.append(new_rand_val)\n",
    "    return np.array(weights).reshape(l, w)\n",
    "\n",
    "\n",
    "def one_hot_encode(targets):\n",
    "    \"\"\"\n",
    "    One hot encodes targets. [4] --> [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    \"\"\"\n",
    "    encoded_data = []\n",
    "    for t in targets:\n",
    "        new_t = np.zeros(10)\n",
    "        new_t[int(t)] = 1.0\n",
    "        encoded_data.append(new_t)\n",
    "    return np.array(encoded_data)\n",
    "\n",
    "\n",
    "def prediction_mse(y_actual, y_pred): # mean-square errors : regression\n",
    "    \"\"\"\n",
    "    Returns mean-square error between actual y and predicted y.\n",
    "    \"\"\"\n",
    "    return 0.5 * sum((y_actual[i] - y_pred[i]) ** 2 for i in range(0, len(y_actual)))\n",
    "\n",
    "\n",
    "def prediction_cel(y_actual, y_pred): # cross-entropy error : classification\n",
    "    \"\"\"\n",
    "    Returns cross-entropy loss between actual y and predicted y.\n",
    "    \"\"\"\n",
    "    if y_actual.ndim == 1:\n",
    "        y_actual = [y_actual]\n",
    "        y_pred = [y_pred]\n",
    "    size = len(y_actual) * len(y_actual[0]) # size=batch_size/classification\n",
    "    return -1.0 / size * np.sum(y_actual * np.log(y_pred) + np.log(1.0 - y_pred) * (1.0 - y_actual))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.ones(shape=x.shape) / (1.0 + np.exp(-x)) # shape=(x.shape)\n",
    "\n",
    "\n",
    "def soft_max(z):\n",
    "    if z.ndim == 1:\n",
    "        z = [z]\n",
    "    exp_z = np.exp(z)\n",
    "    sums = np.sum(exp_z, axis=1, keepdims=True)\n",
    "    return exp_z / sums\n",
    "\n",
    "\n",
    "def pad_image(img_array, top_pad, bottom_pad, left_pad, right_pad):\n",
    "    \"\"\"\n",
    "    Pads the width and height dimensions of an image array or batch of image arrays\n",
    "    with zeros according to padding parameters, and returns a new padded array.\n",
    "    img_array can be a single flat image with dimensions (height, width), an image\n",
    "    with depth with dimensions (depth, height, width), or a batch of images with depth\n",
    "    with dimensions (batch size, depth, height, width).\n",
    "    \"\"\"\n",
    "    img_height = img_array.shape[-2]\n",
    "    img_width = img_array.shape[-1]\n",
    "\n",
    "    # Set the correct shape for the padded version for 2, 3, or 4 dimensions\n",
    "    padded_shape = list(img_array.shape)\n",
    "    padded_shape[-2] += top_pad + bottom_pad\n",
    "    padded_shape[-1] += left_pad + right_pad\n",
    "\n",
    "    padded_img = np.zeros(padded_shape)\n",
    "\n",
    "    if len(img_array.shape) == 2:\n",
    "        padded_img[top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "    elif len(img_array.shape) == 3:\n",
    "        padded_img[:, top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "    else:\n",
    "        padded_img[:, :, top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "def flat_img_to_conv_stack(img, window_size, stride):\n",
    "    \"\"\"\n",
    "    Given a flat image, returns a convolutional stack obtained by passing a square\n",
    "    window across the image (left to right along the top, then next row down, etc).\n",
    "    Each window is unrolled into a single 1-D row, and the stack has dimensions\n",
    "    number_of_windows x window_size^2.\n",
    "    \"\"\"\n",
    "    img_height, img_width = img.shape\n",
    "    unrolled_window_size = window_size ** 2\n",
    "    conv_stack = []\n",
    "\n",
    "    for i in range(0, img_height - window_size + 1, stride):\n",
    "        for j in range(0, img_width - window_size + 1, stride):\n",
    "            conv_stack.append(img[i: i + window_size, j:j + window_size].reshape(unrolled_window_size))\n",
    "\n",
    "    return np.array(conv_stack)\n",
    "\n",
    "\n",
    "def deep_img_to_conv_stack(img, window_size, stride):\n",
    "    \"\"\"\n",
    "    Given an image with depth, returns a convolutional stack obtained by passing a square prism\n",
    "    window with matching depth across the image (left to right along the top, then next row down, etc).\n",
    "    Each window prism is unrolled into a single 1-D row, and the stack has dimensions\n",
    "    (number_of_windows) by (window_size^2 * depth).\n",
    "    \"\"\"\n",
    "    img_depth, img_height, img_width = img.shape\n",
    "    unrolled_window_size = window_size ** 2 * img_depth\n",
    "    conv_stack = []\n",
    "\n",
    "    for i in range(0, img_height - window_size + 1, stride):\n",
    "        for j in range(0, img_width - window_size + 1, stride):\n",
    "            conv_stack.append(img[:, i: i + window_size, j:j + window_size].reshape(unrolled_window_size))\n",
    "\n",
    "    return np.array(conv_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding\n",
    "\n",
    "- 이미지 데이터의 rank를 잘 파악해야합니다.\n",
    "- 이미지의 rank가 상황마다 어떤식으로 표현되는지 파악해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding function definition\n",
    "def pad_image(img_array, top_pad, bottom_pad, left_pad, right_pad):\n",
    "    \"\"\"\n",
    "    Pads the width and height dimensions of an image array or batch of image arrays\n",
    "    with zeros according to padding parameters, and returns a new padded array.\n",
    "    \n",
    "    img_array can be a single flat image with dimensions (height, width), \n",
    "    an image with depth(channel) with dimensions (depth, height, width),  \n",
    "    or a batch of images with depth with dimensions (batch size, depth, height, width).\n",
    "    \n",
    "    ---------------------------------------------------------------------------------------\n",
    "    img_array : image data\n",
    "    top_pad: top space\n",
    "    bottom_pad :bottom space\n",
    "    left_pad : left space\n",
    "    right_pad : right space\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    img_height = img_array.shape[-2]\n",
    "    img_width = img_array.shape[-1]\n",
    "\n",
    "    # Set the correct shape for the padded version for 2, 3, or 4 dimensions\n",
    "    padded_shape = list(img_array.shape)\n",
    "    padded_shape[-2] += top_pad + bottom_pad # height setting\n",
    "    padded_shape[-1] += left_pad + right_pad # weight setting\n",
    "\n",
    "    padded_img = np.zeros(padded_shape) # all zero\n",
    "\n",
    "    if len(img_array.shape) == 2: # shape=(width, height)\n",
    "        padded_img[top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "    elif len(img_array.shape) == 3: # shape=(depth, width, height)\n",
    "        padded_img[:, top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "    else: # shape=(depth, channel, width, height)\n",
    "        padded_img[:, :, top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "\n",
    "    return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight_array(l, w, stddev=None, relu=False, sigma_cutoff=2.0):\n",
    "    \"\"\"\n",
    "    Initializes a weight array with l rows and w columns.\n",
    "    If stddev is not specified, default initialization is designed to create a variance of 1.0,\n",
    "    meaning stddev is sqrt(1 / N_in). If the weight array is going to be used with relu\n",
    "    activation, the default stddev will be sqrt(2 / N_in), since presumably half the neurons\n",
    "    won't fire.\n",
    "    sigma_cutoff determines the max number of stddevs away from 0 an initialized value can be.\n",
    "    \"\"\"\n",
    "    if stddev is None:\n",
    "        if relu:\n",
    "            stddev = (2.0 / l) ** 0.5\n",
    "        else:\n",
    "            stddev = (1.0 / l) ** 0.5\n",
    "\n",
    "    weights = []\n",
    "    while len(weights) < l * w:\n",
    "        new_rand_val = np.random.randn() * stddev\n",
    "        if abs(new_rand_val) < sigma_cutoff * stddev: # sigma cutoff가 weight를 선택함\n",
    "            weights.append(new_rand_val)\n",
    "    return np.array(weights).reshape(l, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "    \"\"\"\n",
    "    Base class for a neural net.\n",
    "    self.layers is a list of layers going in order from input to output.\n",
    "    With this structure, activation functions count as separate layers.\n",
    "    self.feed_forward uses a series of layer forward_pass methods to go\n",
    "    from an input into an output and also sets the input and output\n",
    "    properties of the corresponding layers.\n",
    "    self.feed_backward uses a series of layer backward_pass methods to\n",
    "    go from output deltas backwards through the network, and modifies\n",
    "    layers if applicable\n",
    "    self.train trains the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers): # layers(레이어의 집합)을 가져온다\n",
    "        self.layers = layers\n",
    "\n",
    "    def feed_forward(self, x_in):\n",
    "        self.layers[0].input = x_in\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            self.layers[i + 1].input = self.layers[i].forward_pass()\n",
    "        self.layers[-1].forward_pass()\n",
    "        return self.layers[-1].output\n",
    "\n",
    "    def feed_backward(self, delta_y_out, backprop_params):\n",
    "        self.layers[-1].output_side_deltas = delta_y_out # 맨 뒷단의 layer를 가져온다\n",
    "        for i in range(len(self.layers) - 1, 0, -1):\n",
    "            \n",
    "            self.layers[i - 1].output_side_deltas = self.layers[i].backward_pass(backprop_params)\n",
    "        self.layers[0].backward_pass(backprop_params)\n",
    "\n",
    "    @staticmethod\n",
    "    def mse_cost(y_predicted, y_actual):\n",
    "        \"\"\"\n",
    "        Returns total mean-square error for predicted values and actual values.\n",
    "        \"\"\"\n",
    "        return ((y_actual - y_predicted)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(Network):\n",
    "    \"\"\"\n",
    "    Classifier network, with an accuracy method and a static cross-entropy loss method\n",
    "    \"\"\"\n",
    "\n",
    "    def accuracy(self, x_input, labels_as_values): # 모델의 정확도\n",
    "        correct = 0.0\n",
    "        all_output = self.feed_forward(x_input)\n",
    "        for logit, label in zip(all_output, labels_as_values):\n",
    "            if np.argmax(logit) == label:\n",
    "                correct += 1\n",
    "        return correct / len(x_input)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_cost(y_predicted, y_actual): \n",
    "        \"\"\"\n",
    "        Returns total mean-square error for predicted values and actual values.\n",
    "        Pads predicted values very close to 0.0 or 1.0 to avoid overflowing cost\n",
    "        \"\"\"\n",
    "        epsilon = 1e-12\n",
    "        y_predicted[y_predicted < epsilon] = epsilon\n",
    "        y_predicted[y_predicted > 1 - epsilon] = 1 - epsilon\n",
    "\n",
    "        size = len(y_actual) * len(y_actual[0])\n",
    "\n",
    "        ce_cost = -1.0 / size * np.sum(y_actual * np.log(y_predicted) + np.log(1.0 - y_predicted) * (1.0 - y_actual))\n",
    "\n",
    "        return ce_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolution layer class\n",
    "\n",
    "- Produces a volume of size W2×H2×D2 where:\n",
    "\n",
    "- W2=(W1−F+2P)/S+1\n",
    "\n",
    "- H2=(H1−F+2P)/S+1 (i.e. width and height are computed equally by symmetry)\n",
    "- D2=K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"\n",
    "    Base class for layers, which will include matrices, activation functions, and\n",
    "    convolution layers.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.output_side_deltas = None\n",
    "        self.input_side_deltas = None\n",
    "\n",
    "    def forward_pass(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer(Layer):\n",
    "    \"\"\"\n",
    "    Fully connected layer in which input is multiplied by a trainable weight matrix\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows, cols, relu=False): \n",
    "        super().__init__()\n",
    "        self.shape = (rows, cols) # row,col 입력받는다\n",
    "        self.w = initialize_weight_array(rows, cols, relu=relu) # W 초기화\n",
    "        self.b = np.zeros(shape=(1, cols))\n",
    "\n",
    "    def forward_pass(self):\n",
    "        self.output = np.dot(self.input, self.w) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        alpha_adj, lam = backprop_params\n",
    "        self.input_side_deltas = np.dot(self.output_side_deltas, self.w.T) # self.output_side_deltas는 입력받는 값\n",
    "        if lam:\n",
    "            self.w *= (1.0 - lam * alpha_adj)\n",
    "        self.w += alpha_adj * np.dot(self.input.T, self.output_side_deltas)\n",
    "        self.b += alpha_adj * self.output_side_deltas.sum(axis=0)\n",
    "        return self.input_side_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidLayer(Layer):\n",
    "    \"\"\"\n",
    "    Sigmoid activation layer. Input and output have the same shape, as do the input-side and\n",
    "    output-side deltas.\n",
    "    \"\"\"\n",
    "    def forward_pass(self):\n",
    "        self.output = 1.0 / (1.0 + np.exp(-self.input))\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        # Backprop parameters are not used.\n",
    "        self.input_side_deltas = self.output_side_deltas * self.output * (1.0 - self.output)\n",
    "        return self.input_side_deltas\n",
    "\n",
    "\n",
    "class SoftmaxLayer(Layer):\n",
    "    \"\"\"\n",
    "    Softmax activation layer, to be used right before output. Backprop is skipped entirely,\n",
    "    under the assumption that this will be used with cross-entropy loss.\n",
    "    \"\"\"\n",
    "    def forward_pass(self):\n",
    "        exp_z = np.exp(self.input)\n",
    "        sums = np.sum(exp_z, axis=1, keepdims=True)\n",
    "        self.output = exp_z / sums\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        # Backprop parameters are not used\n",
    "        self.input_side_deltas = self.output_side_deltas\n",
    "        return self.input_side_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LReLULayer(Layer):\n",
    "    \"\"\"\n",
    "    Leaky ReLU activation layer. Input and output have the same shape, as do the input-side and\n",
    "    output-side deltas.\n",
    "    \"\"\"\n",
    "    def __init__(self, a=0.01):\n",
    "        super().__init__() # Layer로부터 상속받는다\n",
    "        self.a = a\n",
    "\n",
    "    def forward_pass(self):\n",
    "        self.output = np.maximum(self.input, self.a * self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        # Backprop parameters are not used.\n",
    "        pos_boolean = self.input >= 0\n",
    "        self.input_side_deltas = self.a * self.output_side_deltas[:]\n",
    "        self.input_side_deltas[pos_boolean] = self.output_side_deltas[pos_boolean]\n",
    "\n",
    "        return self.input_side_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayerWithDropout(Layer):\n",
    "    \"\"\"\n",
    "    Fully connected layer in which input is multiplied by a trainable weight matrix, with\n",
    "    dropout that can be turned on or off.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows, cols, keep_prob, relu=False):\n",
    "        super().__init__()\n",
    "        self.shape = (rows, cols)\n",
    "        self.w = initialize_weight_array(rows, cols, relu=relu)\n",
    "        self.b = np.zeros(shape=(1, cols))\n",
    "        self.keep_prob = keep_prob\n",
    "        self.dropout_on = False\n",
    "        self.keep_mask = None\n",
    "\n",
    "    def forward_pass(self):\n",
    "        adjusted_weight = self.w.copy()\n",
    "\n",
    "        if self.dropout_on:\n",
    "            self.keep_mask = np.random.binomial([np.ones(self.w.shape)], self.keep_prob)[0] * (1.0 / self.keep_prob)\n",
    "            adjusted_weight *= self.keep_mask\n",
    "\n",
    "        self.output = np.dot(self.input, adjusted_weight) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        if not self.dropout_on:\n",
    "            warnings.warn(\"Warning: Backprop is being run without dropout, which is probably an error.\")\n",
    "        alpha_adj, _ = backprop_params   # Not using L2 regularization\n",
    "\n",
    "        adjusted_weight = self.w.copy()\n",
    "\n",
    "        if self.dropout_on:\n",
    "            adjusted_weight *= self.keep_mask\n",
    "\n",
    "        self.input_side_deltas = np.dot(self.output_side_deltas, adjusted_weight.T)\n",
    "\n",
    "        weight_delta = alpha_adj * np.dot(self.input.T, self.output_side_deltas)\n",
    "\n",
    "        if self.dropout_on:\n",
    "            weight_delta *= self.keep_mask\n",
    "\n",
    "        self.w += weight_delta\n",
    "        self.b += alpha_adj * self.output_side_deltas.sum(axis=0)\n",
    "\n",
    "        return self.input_side_deltas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer(Layer):\n",
    "\n",
    "    def __init__(self,channels_out,channels_in,window_size,stride,pad=False,relu=True):\n",
    "        super().__init__()\n",
    "        self.channels_out=channels_out # output의 depth\n",
    "        self.channels_in=channels_in # input의 depth\n",
    "        self.window_size=window_size \n",
    "        self.stride=stride\n",
    "        self.pad=pad\n",
    "        \n",
    "        self.shape_4d=(channels_out,channels_in,window_size,window_size)\n",
    "        # filter 정의\n",
    "        # l :  channels_in*window_size**2\n",
    "        # W :  channels_out ?? filter 개수\n",
    "        self.filter_2d=initialize_weight_array(channels_in*window_size**2,channels_out,relu=relu)\n",
    "        self.filter_4d=self.filter_2d.reshape(self.shape_4d)\n",
    "        self.b=np.zeros(shape=(1,channels_out))\n",
    "        \n",
    "        self.batch_size=None\n",
    "        self.padded_input=None\n",
    "        self.top_pad = None\n",
    "        self.bottom_pad = None\n",
    "        self.left_pad = None\n",
    "        self.right_pad = None\n",
    "        self.reshaped_input = None\n",
    "        self.output_height = None\n",
    "        self.output_width = None\n",
    "    \n",
    "    def forward_pass(self):\n",
    "        if self.pad:\n",
    "            # pad 값 연산\n",
    "            # window_size에 따라 변화한다. 하지만 다르게 줄 수도 있다. default 값 설정하기\n",
    "            # cs231n 노트 참고 : http://cs231n.github.io/convolutional-networks/\n",
    "            _,_,input_h,input_w=self.input.shape\n",
    "            self.top_pad=(self.window_size-1)//2 # // operation : 몫\n",
    "            self.bottom_pad=self.window_size//2-(input_h-1)%self.stride\n",
    "            self.left_pad=(self.window_size-1)//2\n",
    "            self.right_pad=(self.window_size//2)-(input_w-1)%self.stride\n",
    "            self.padded_input=pad_image(self.input,self.top_pad,self.bottom_pad,self.left_pad,self.right_pad)\n",
    "            \n",
    "        else : # pad값이 안들어오면, padded된 것이라고 간주\n",
    "            self.padded_input=self.input\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.reshaped_input=self.img_batch_to_conv_stacks() # 이해하기 \n",
    "        self.batch_size=self.input.shape[0]\n",
    "        \n",
    "        reshaped_output=np.dot(self.reshaped_input,self.filter_2d)+self.b # 이해해보기\n",
    "        self.output=reshaped_output.T.reshape(self.channels_out, self.batch_size,self.output_height,self.output_width).transpose(1,0,2,3)\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self,backprop_params):\n",
    "        alpha_adj, lam= backprop_params\n",
    "        \n",
    "        # self.output_side_deltas : ?? 어디서 나온것인지 확인하기\n",
    "        # transpose : 행렬의 axis의 이동\n",
    "        reshaped_output_side_deltas=self.output_side_deltas.transpose(1,0,2,3).reshape(self.channels_out,-1).T\n",
    "        \n",
    "        reshaped_input_side_deltas=np.dot(reshaped_output_side_deltas, self.filter_2d.T)\n",
    "        \n",
    "        self.input_side_deltas=self.conv_stack_deltas_to_input_deltas(reshaped_input_side_deltas)\n",
    "        \n",
    "        if self.pad:\n",
    "            new_bottom_index=self.input_side_deltas.shape[2]-self.bottom_pad\n",
    "            new_right_index=self.input_side_deltas.shape[3]-self.right_pad\n",
    "            self.input_side_deltas=self.input_side_deltas[:,:,self.top_pad:new_bottom_index,\\\n",
    "                                                         self.left_pad:new_right_index]\n",
    "            \n",
    "        self.filter_2d+=alpha_adj*np.dot(self.reshaped_input.T,reshaped_output_side_deltas)\n",
    "        self.filter_4d=self.filter_2d.T.reshape(self.shape_4d)\n",
    "        \n",
    "        self.b+=alpha_adj*self.output_side_deltas.sum(axis=(0,2,3))\n",
    "        \n",
    "        \n",
    "            \n",
    "        if lam:\n",
    "            self.filter_2d*=(1.0-lam*alpha_adj)\n",
    "            self.filter_4d*=(1.0-lam*alpha_adj)\n",
    "            \n",
    "        return self.input_side_deltas\n",
    "    \n",
    "    # input_data를 filter와 inner product할 수 있게 바꿔준다.\n",
    "    # cnn의 중요한 부분\n",
    "    def img_batch_to_conv_stacks(self):\n",
    "        \"\"\"\n",
    "        Takes the current input, a batch of images with depth, and sets the reshape_input property to be series\n",
    "        of convolutional stacks obtained by passing a square prism window with matching depth across each image\n",
    "        (left to right along the top, then next row down, etc, then same for remaining channels, then next image).\n",
    "        Each window prism is unrolled into a single 1-D row, and the stack array has dimensions\n",
    "        (batch size * number_of_windows) by (window_size^2 * depth).\n",
    "        \"\"\"\n",
    "        batch_size, img_depth, img_height,img_weight=self.padded_input.shape\n",
    "        unrolled_window_size=self.window_size**2*img_depth\n",
    "        \n",
    "        # output의 width, height 정의, depth는 filter의 개수\n",
    "        self.output_height=(img_height-self.window_size)//self.stride+1\n",
    "        self.output_width=(img_weight-self.window_size)//self.stride+1\n",
    "        \n",
    "        conv_stack=[]\n",
    "        \n",
    "        for k in range(0, batch_size): # batch끼리\n",
    "            # height기준으로, img_height-self.window_size+1 범위에서 ,stride만큼 이동 \n",
    "            for i in range(0, img_height-self.window_size+1,self.stride): \n",
    "                # weight기준으로, img_weight-self.window_size+1 범위에서 ,stride만큼 이동\n",
    "                for j in range(0, img_weight-self.window_size+1,self.stride): \n",
    "                    conv_stack.append(self.padded_input[k,:,i:i+self.window_size,j:j+self.window_size]\\\n",
    "                                     .reshape(unrolled_window_size)) # 내적을 하기 위한 전처리\n",
    "                    \n",
    "        # conv_stack shape가 어떻게 되는지 확인하기\n",
    "                    \n",
    "        return np.array(conv_stack)\n",
    "        \n",
    "    def conv_stack_deltas_to_input_deltas(self, reshaped_input_side_deltas):\n",
    "        reshaped_input_side_deltas=reshaped_input_side_deltas.reshape(self.batch_size, self.output_height, self.output_width,-1)\n",
    "        deconvolved_input_side_deltas=np.zeros(self.padded_input.shape)\n",
    "        \n",
    "        for k in range(self.batch_size):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    patch_to_add=reshaped_input_side_deltas[k][i][j].\\\n",
    "                    reshape(self.channels_in,self.window_size,self.window_size)\n",
    "                    \n",
    "                    in_side_i=self.stride*i\n",
    "                    in_side_j=self.stride*j\n",
    "                    deconvolved_input_side_deltas[0,0:self.channels_in,in_side_i:in_side_i+self.window_size,\\\n",
    "                                                 in_side_j:in_side_j+self.window_size]+=patch_to_add\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "        return deconvolved_input_side_deltas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionFullyConnectedBridge(Layer):\n",
    "    \"\"\"\n",
    "    Layer that connects a 4-D (batch_size, conv_output_channels, conv_output_height, conv_output_width) input to a\n",
    "    2-D output (batch_size, conv_output_channels * conv_output_height * conv_output_width)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conv_output_channels, conv_output_height, conv_output_width):\n",
    "        super().__init__()\n",
    "        self.conv_output_channels = conv_output_channels\n",
    "        self.conv_output_height = conv_output_height\n",
    "        self.conv_output_width = conv_output_width\n",
    "\n",
    "        self.batch_size = None\n",
    "\n",
    "    def forward_pass(self):\n",
    "        self.batch_size = self.input.shape[0]\n",
    "        self.output = self.input.reshape(self.batch_size, -1)\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        _, _ = backprop_params   # Ignoring backprop params, since there's nothing to train\n",
    "\n",
    "        self.input_side_deltas = self.output_side_deltas.reshape(self.batch_size, self.conv_output_channels,\n",
    "                                                                 self.conv_output_height, self.conv_output_width)\n",
    "        return self.input_side_deltas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(regression_net, train, test, alpha, epochs, lam=0.0, verbose=False):\n",
    "    \"\"\"\n",
    "    Training tool for regressions--simpler than classification tool, currently not using\n",
    "    validation or batches.\n",
    "    \"\"\"\n",
    "    print(\"Training network with alpha={}, lambda={} for {} epochs...\".format(alpha, lam, epochs))\n",
    "    x_training, x_testing = train['x'], test['x']\n",
    "    y_training, y_testing = train['y_'], test['y_']\n",
    "\n",
    "    training_size = x_training.shape[0]\n",
    "\n",
    "    for e in range(1, epochs + 1):\n",
    "        delta_y = y_training - regression_net.feed_forward(x_training)\n",
    "        regression_net.feed_backward(delta_y, [alpha / training_size, lam])\n",
    "        if verbose and e % 100 == 0:\n",
    "            print(\"Epoch {:>3}\\t Training loss: {:>5.3f}\".format\n",
    "                  (e, regression_net.mse_cost(y_predicted=regression_net.layers[-1].output, y_actual=y_training)))\n",
    "    print(\"Training complete. Testing loss: {:>5.3f}\".format\n",
    "          (regression_net.mse_cost(y_predicted=regression_net.feed_forward(x_testing), y_actual=y_testing)))\n",
    "\n",
    "\n",
    "def train_classifier_model(classifier, train, valid, test, alpha, batch_size, epochs,\n",
    "                           lam=0.0, dropout_model=False, verbose=False):\n",
    "\n",
    "    print(\"Training network with alpha={}, lambda={}, batch size={} for {} epochs...\".format(\n",
    "          alpha, lam, batch_size, epochs))\n",
    "\n",
    "    x_training, x_validation, x_testing = train['x'], valid['x'], test['x']\n",
    "    y_training_int, y_validation_int, y_testing_int = train['y_as_int'], valid['y_as_int'], test['y_as_int']\n",
    "    y_training_one_hot, y_validation_one_hot, y_testing_one_hot = train['y_'], valid['y_'], test['y_']\n",
    "\n",
    "    num_batches = len(x_training) // batch_size\n",
    "\n",
    "    for e in range(1, epochs + 1):\n",
    "        training_loss = 0.0\n",
    "        for j in range(num_batches):\n",
    "            start_index = j * batch_size\n",
    "            end_index = start_index + batch_size\n",
    "            x = x_training[start_index: end_index]\n",
    "            y_ = y_training_one_hot[start_index: end_index]\n",
    "\n",
    "            if dropout_model:\n",
    "                set_dropout_boolean(classifier, True)\n",
    "\n",
    "            delta_y = y_ - classifier.feed_forward(x) # delta_y == self.output_side_deltas\n",
    "            classifier.feed_backward(delta_y, (alpha / num_batches, lam))\n",
    "\n",
    "            if dropout_model:\n",
    "                set_dropout_boolean(classifier, False)\n",
    "\n",
    "            training_loss += classifier.cross_entropy_cost(y_predicted=classifier.layers[-1].output, y_actual=y_)\n",
    "\n",
    "        if verbose and e % 1 == 0:\n",
    "            print(\"Epoch {:>3}\\t Training loss: {:>5.3f}\\t Validation acc: {:>5.3f}\".format\n",
    "                  (e, training_loss / num_batches, classifier.accuracy(x_validation, y_validation_int)))\n",
    "\n",
    "    print(\"Training complete. Testing loss: {:>5.3f} \\t Testing accuracy: {:>5.3f}\".format\n",
    "          (classifier.cross_entropy_cost(y_predicted=classifier.feed_forward(x_testing), y_actual=y_testing_one_hot),\n",
    "           classifier.accuracy(x_testing, y_testing_int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classifier(layer_sizes):\n",
    "    \"\"\"\n",
    "    Returns a classifier object with the specified fully connected layer sizes.\n",
    "    Each fully connected layer except for the last is followed by a sigmoid\n",
    "    activation layer. Last fully connected layer is followed by a softmax layer.\n",
    "    For an MNIST network layer sizes might be something like [784, 150, 25, 10].\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    for i in range(len(layer_sizes) - 2):\n",
    "        layers.append(FullyConnectedLayer(layer_sizes[i], layer_sizes[i + 1]))\n",
    "        layers.append(SigmoidLayer())\n",
    "    layers.append(FullyConnectedLayer(layer_sizes[-2], layer_sizes[-1]))\n",
    "    layers.append(SoftmaxLayer())\n",
    "    return Classifier(layers)\n",
    "\n",
    "\n",
    "def make_lrelu_classifier(layer_sizes):\n",
    "    \"\"\"\n",
    "    Returns a classifier object with the specified fully connected layer sizes.\n",
    "    Each fully connected layer except for the last is followed by a LReLU\n",
    "    activation layer. Last fully connected layer is followed by a softmax layer.\n",
    "    For an MNIST network layer sizes might be something like [784, 150, 25, 10].\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    for i in range(len(layer_sizes) - 2):\n",
    "        layers.append(FullyConnectedLayer(layer_sizes[i], layer_sizes[i + 1], relu=True))\n",
    "        layers.append(LReLULayer())\n",
    "    layers.append(FullyConnectedLayer(layer_sizes[-2], layer_sizes[-1]))\n",
    "    layers.append(SoftmaxLayer())\n",
    "    return Classifier(layers)\n",
    "\n",
    "\n",
    "def make_lrelu_classifier_with_dropout(layer_sizes, keep_prob):\n",
    "    \"\"\"\n",
    "    Returns a classifier object with the specified fully connected layer sizes.\n",
    "    Each fully connected layer except for the last is followed by a LReLU\n",
    "    activation layer. Last fully connected layer is followed by a softmax layer.\n",
    "    For an MNIST network layer sizes might be something like [784, 150, 25, 10].\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    for i in range(len(layer_sizes) - 2):\n",
    "        layers.append(FullyConnectedLayerWithDropout(layer_sizes[i], layer_sizes[i + 1], keep_prob, relu=True))\n",
    "        layers.append(LReLULayer())\n",
    "    layers.append(FullyConnectedLayerWithDropout(layer_sizes[-2], layer_sizes[-1], keep_prob))\n",
    "    layers.append(SoftmaxLayer())\n",
    "    return Classifier(layers)\n",
    "\n",
    "\n",
    "def set_dropout_boolean(network, dropout_boolean):\n",
    "    for layer in network.layers:\n",
    "        if type(layer).__name__ == 'FullyConnectedLayerWithDropout':\n",
    "            layer.dropout_on = dropout_boolean\n",
    "\n",
    "\n",
    "def old_make_cnn_classifier():\n",
    "    \"\"\"\n",
    "    Draft of a CNN classifier\n",
    "    \"\"\"\n",
    "    layers = [ConvolutionLayer(channels_out=32, channels_in=1, window_size=5, stride=2, pad=True),\n",
    "              LReLULayer(),\n",
    "              ConvolutionLayer(channels_out=64, channels_in=32, window_size=5, stride=2, pad=True),\n",
    "              LReLULayer(),\n",
    "              ConvolutionFullyConnectedBridge(64, 7, 7),\n",
    "              FullyConnectedLayerWithDropout(3136, 180, keep_prob=0.5),\n",
    "              LReLULayer(),\n",
    "              FullyConnectedLayerWithDropout(180, 10, keep_prob=0.5),\n",
    "              SoftmaxLayer()]\n",
    "    print(\"\"\"[ConvolutionLayer(channels_out=32, channels_in=1, window_size=5, stride=2, pad=True),\n",
    "              LReLULayer(),\n",
    "              ConvolutionLayer(channels_out=64, channels_in=32, window_size=5, stride=2, pad=True),\n",
    "              LReLULayer(),\n",
    "              ConvolutionFullyConnectedBridge(64, 7, 7),\n",
    "              FullyConnectedLayerWithDropout(3136, 180, keep_prob=0.5),\n",
    "              LReLULayer(),\n",
    "              FullyConnectedLayerWithDropout(180, 10, keep_prob=0.5),\n",
    "              SoftmaxLayer()]\"\"\")\n",
    "    return Classifier(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn_classifier(input_shape, conv_layer_list, fully_connected_layer_list=None, keep_prob=0.5):\n",
    "    \"\"\"\n",
    "    Function to create CNN classifier, given the following parameters:\n",
    "    input_shape: tuple of (depth, height, width) which is (1, 28, 28) for MNIST\n",
    "    conv_layer_list: list of layer parameters in the form (window_size, stride, out_channels, padded_boolean)\n",
    "    fully_connected_layer_list: list of optional additional fully connected layer sizes, where a list [1000, 200]\n",
    "      would result in two additional layers after the convolution layers, for a total of three layers. These would be\n",
    "      ? to 1000, 1000 to 200, and 200 to 10, where the ? is determined by the output of the final convolutional layer.\n",
    "    keep_prob: the keep probability for the dropout in the fully connected layers.\n",
    "    \"\"\"\n",
    "\n",
    "    if fully_connected_layer_list is None:\n",
    "        fully_connected_layer_list = []\n",
    "\n",
    "    current_depth, current_height, current_width = input_shape\n",
    "    layers = []\n",
    "\n",
    "    print(\"Creating CNN with the following layers:\")\n",
    "\n",
    "    for win_size, stride, out_chan, pad_bool in conv_layer_list:\n",
    "        layers.append(ConvolutionLayer(channels_out=out_chan, channels_in=current_depth, window_size=win_size,\n",
    "                                       stride=stride, pad=pad_bool))\n",
    "        print(\"\\tConvolution layer. Window size: ({}, {})\\tStride: ({}, {})\\tOutput channels: {:3}\\tPadding: {}\".format(\n",
    "              win_size, win_size, stride, stride, out_chan, pad_bool))\n",
    "\n",
    "        layers.append(LReLULayer())\n",
    "        current_depth = out_chan\n",
    "        if pad_bool:\n",
    "            current_height += win_size - 1 - (current_height - 1) % stride\n",
    "            current_width += win_size - 1 - (current_width - 1) % stride\n",
    "        current_height = (current_height - win_size) // stride + 1\n",
    "        current_width = (current_width - win_size) // stride + 1\n",
    "\n",
    "    layers.append(ConvolutionFullyConnectedBridge(current_depth, current_height, current_width))\n",
    "\n",
    "    fully_connected_size = current_depth * current_height * current_width\n",
    "\n",
    "    for layer_size in fully_connected_layer_list:\n",
    "        layers.append(FullyConnectedLayerWithDropout(fully_connected_size, layer_size, keep_prob=keep_prob))\n",
    "        print(\"\\tFully connected layer. {} to {} with keep probability {}\".format(\n",
    "              fully_connected_size, layer_size, keep_prob))\n",
    "        fully_connected_size = layer_size\n",
    "        layers.append(LReLULayer())\n",
    "\n",
    "    layers.append(FullyConnectedLayerWithDropout(fully_connected_size, 10, keep_prob=keep_prob))\n",
    "\n",
    "    print(\"\\tFully connected layer. {} to {} with keep probability {}\".format(\n",
    "          fully_connected_size, 10, keep_prob))\n",
    "\n",
    "    layers.append(SoftmaxLayer())\n",
    "\n",
    "    return Classifier(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, testing = import_and_prepare_mnist_data(0.1, 0.1, flat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CNN with the following layers:\n",
      "\tConvolution layer. Window size: (5, 5)\tStride: (2, 2)\tOutput channels:  64\tPadding: True\n",
      "\tConvolution layer. Window size: (5, 5)\tStride: (2, 2)\tOutput channels: 128\tPadding: True\n",
      "\tFully connected layer. 6272 to 400 with keep probability 0.5\n",
      "\tFully connected layer. 400 to 10 with keep probability 0.5\n",
      "Classifier created\n",
      "Training network with alpha=1.0, lambda=0.01, batch size=64 for 50 epochs...\n"
     ]
    }
   ],
   "source": [
    "conv_layer_parameters = [(5, 2, 64, True), (5, 2, 128, True)]\n",
    "fully_connected_parameters = [400]\n",
    "\n",
    "cnn_classifier = make_cnn_classifier((1, 28, 28), conv_layer_parameters, fully_connected_parameters)\n",
    "\n",
    "print(\"Classifier created\")\n",
    "\n",
    "train_classifier_model(cnn_classifier, training, validation, testing, alpha=1.0, \\\n",
    "                       batch_size=64,epochs=50, lam=0.01, dropout_model=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
