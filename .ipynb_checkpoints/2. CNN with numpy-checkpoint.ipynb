{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network\n",
    "\n",
    "### index\n",
    "\n",
    "- filter\n",
    "- padding\n",
    "- stride\n",
    "- activation\n",
    "- FC layer\n",
    "\n",
    "### motivation\n",
    "\n",
    "CNN의 내부동작원리의 이해를 돕기 위한 자료\n",
    "\n",
    "### data\n",
    "\n",
    "MNIST dataset\n",
    "\n",
    "### reference \n",
    "- cs231n convolution neural network\n",
    "- https://github.com/raphey/numpy-cnn/blob/master/nn_util.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mnist data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset download and prepare datasetting\n",
    "def import_and_prepare_mnist_data(valid_portion=0.1, test_portion=0.1, flat=True):\n",
    "    \"\"\"\n",
    "    Imports mnist data, shuffles it, and splits it into training, validation, and testing sets.\n",
    "    If flat parameter is set to False, each image will be reshaped from (784) to (28 x 28 x 1), for convolution.\n",
    "    training, validation, and testing are dicts with three keys each:\n",
    "      'x': the image data\n",
    "      'y_': the one-hot encoded labels\n",
    "      'y_as_int': the labels as integers, for quick accuracy checking\n",
    "    \"\"\"\n",
    "\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    data_size = len(mnist['data'])\n",
    "\n",
    "    img_data, int_targets = shuffle_data(mnist)\n",
    "\n",
    "    if not flat:\n",
    "        img_data = img_data.reshape(-1, 1, 28, 28)\n",
    "\n",
    "    scaled_data = img_data / 255.0\n",
    "\n",
    "    int_targets = int_targets.astype(int)\n",
    "\n",
    "    one_hots = one_hot_encode(int_targets)\n",
    "\n",
    "    # Cutoff indices between training/validation and validation/testing\n",
    "    validation_start = int((1.0 - valid_portion - test_portion) * data_size)\n",
    "    testing_start = int((1.0 - test_portion) * data_size)\n",
    "\n",
    "    train = {'x': scaled_data[:validation_start],\n",
    "             'y_': one_hots[:validation_start],\n",
    "             'y_as_int': int_targets[:validation_start]}\n",
    "\n",
    "    valid = {'x': scaled_data[validation_start: testing_start],\n",
    "             'y_': one_hots[validation_start: testing_start],\n",
    "             'y_as_int': int_targets[validation_start: testing_start]}\n",
    "\n",
    "    test = {'x': scaled_data[testing_start:],\n",
    "            'y_': one_hots[testing_start:],\n",
    "            'y_as_int': int_targets[testing_start:]}\n",
    "\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding\n",
    "\n",
    "- 이미지 데이터의 rank를 잘 파악해야합니다.\n",
    "- 이미지의 rank가 상황마다 어떤식으로 표현되는지 파악해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding function definition\n",
    "def pad_image(img_array, top_pad, bottom_pad, left_pad, right_pad):\n",
    "    \"\"\"\n",
    "    Pads the width and height dimensions of an image array or batch of image arrays\n",
    "    with zeros according to padding parameters, and returns a new padded array.\n",
    "    \n",
    "    img_array can be a single flat image with dimensions (height, width), \n",
    "    an image with depth(channel) with dimensions (depth, height, width),  \n",
    "    or a batch of images with depth with dimensions (batch size, depth, height, width).\n",
    "    \n",
    "    ---------------------------------------------------------------------------------------\n",
    "    img_array : image data\n",
    "    top_pad: top space\n",
    "    bottom_pad :bottom space\n",
    "    left_pad : left space\n",
    "    right_pad : right space\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    img_height = img_array.shape[-2]\n",
    "    img_width = img_array.shape[-1]\n",
    "\n",
    "    # Set the correct shape for the padded version for 2, 3, or 4 dimensions\n",
    "    padded_shape = list(img_array.shape)\n",
    "    padded_shape[-2] += top_pad + bottom_pad # height setting\n",
    "    padded_shape[-1] += left_pad + right_pad # weight setting\n",
    "\n",
    "    padded_img = np.zeros(padded_shape) # all zero\n",
    "\n",
    "    if len(img_array.shape) == 2: # shape=(width, height)\n",
    "        padded_img[top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "    elif len(img_array.shape) == 3: # shape=(depth, width, height)\n",
    "        padded_img[:, top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "    else: # shape=(depth, channel, width, height)\n",
    "        padded_img[:, :, top_pad: top_pad + img_height, left_pad: left_pad + img_width] = img_array\n",
    "\n",
    "    return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weight_array(l, w, stddev=None, relu=False, sigma_cutoff=2.0):\n",
    "    \"\"\"\n",
    "    Initializes a weight array with l rows and w columns.\n",
    "    If stddev is not specified, default initialization is designed to create a variance of 1.0,\n",
    "    meaning stddev is sqrt(1 / N_in). If the weight array is going to be used with relu\n",
    "    activation, the default stddev will be sqrt(2 / N_in), since presumably half the neurons\n",
    "    won't fire.\n",
    "    sigma_cutoff determines the max number of stddevs away from 0 an initialized value can be.\n",
    "    \"\"\"\n",
    "    if stddev is None:\n",
    "        if relu:\n",
    "            stddev = (2.0 / l) ** 0.5\n",
    "        else:\n",
    "            stddev = (1.0 / l) ** 0.5\n",
    "\n",
    "    weights = []\n",
    "    while len(weights) < l * w:\n",
    "        new_rand_val = np.random.randn() * stddev\n",
    "        if abs(new_rand_val) < sigma_cutoff * stddev: # sigma cutoff가 weight를 선택함\n",
    "            weights.append(new_rand_val)\n",
    "    return np.array(weights).reshape(l, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolution layer class\n",
    "\n",
    "- Produces a volume of size W2×H2×D2 where:\n",
    "\n",
    "- W2=(W1−F+2P)/S+1\n",
    "\n",
    "- H2=(H1−F+2P)/S+1 (i.e. width and height are computed equally by symmetry)\n",
    "- D2=K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"\n",
    "    Base class for layers, which will include matrices, activation functions, and\n",
    "    convolution layers.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "        self.output_side_deltas = None\n",
    "        self.input_side_deltas = None\n",
    "\n",
    "    def forward_pass(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidLayer(Layer):\n",
    "    \"\"\"\n",
    "    Sigmoid activation layer. Input and output have the same shape, as do the input-side and\n",
    "    output-side deltas.\n",
    "    \"\"\"\n",
    "    def forward_pass(self):\n",
    "        self.output = 1.0 / (1.0 + np.exp(-self.input))\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        # Backprop parameters are not used.\n",
    "        self.input_side_deltas = self.output_side_deltas * self.output * (1.0 - self.output)\n",
    "        return self.input_side_deltas\n",
    "\n",
    "\n",
    "class SoftmaxLayer(Layer):\n",
    "    \"\"\"\n",
    "    Softmax activation layer, to be used right before output. Backprop is skipped entirely,\n",
    "    under the assumption that this will be used with cross-entropy loss.\n",
    "    \"\"\"\n",
    "    def forward_pass(self):\n",
    "        exp_z = np.exp(self.input)\n",
    "        sums = np.sum(exp_z, axis=1, keepdims=True)\n",
    "        self.output = exp_z / sums\n",
    "        return self.output\n",
    "\n",
    "    def backward_pass(self, backprop_params):\n",
    "        # Backprop parameters are not used\n",
    "        self.input_side_deltas = self.output_side_deltas\n",
    "        return self.input_side_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionLayer(Layer):\n",
    "\n",
    "    def __init__(self,channels_out,channels_in,window_size,stride,pad=False,relu=True):\n",
    "        super().__init__()\n",
    "        self.channels_out=channels_out # output의 depth\n",
    "        self.channels_in=channels_in # input의 depth\n",
    "        self.window_size=window_size \n",
    "        self.stride=stride\n",
    "        self.pad=pad\n",
    "        \n",
    "        self.shape_4d=(channels_out,channels_in,window_size,window_size)\n",
    "        # filter 정의\n",
    "        # l :  channels_in*window_size**2\n",
    "        # W :  channels_out ?? filter 개수\n",
    "        self.filter_2d=initialize_weight_array(channels_in*window_size**2,channels_out,relu=relu)\n",
    "        self.filter_4d=self.filter_2d.reshape(self.shape_4d)\n",
    "        self.b=np.zeros(shape=(1,channels_out))\n",
    "        \n",
    "        self.batch_size=None\n",
    "        self.padded_input=None\n",
    "        self.top_pad = None\n",
    "        self.bottom_pad = None\n",
    "        self.left_pad = None\n",
    "        self.right_pad = None\n",
    "        self.reshaped_input = None\n",
    "        self.output_height = None\n",
    "        self.output_width = None\n",
    "    \n",
    "    def forward_pass(self):\n",
    "        if self.pad:\n",
    "            # pad 값 연산\n",
    "            # window_size에 따라 변화한다. 하지만 다르게 줄 수도 있다. default 값 설정하기\n",
    "            # cs231n 노트 참고 : http://cs231n.github.io/convolutional-networks/\n",
    "            _,_,input_h,input_w=self.input.shape\n",
    "            self.top_pad=(self.window_size-1)//2 # // operation : 몫\n",
    "            self.bottom_pad=self.window_size//2-(input_h-1)%self.stride\n",
    "            self.left_pad=(self.window_size-1)//2\n",
    "            self.right_pad=(self.window_size//2)-(input_w-1)%self.stride\n",
    "            self.padded_input=pad_image(self.input,self.top_pad,self.bottom_pad,self.left_pad,self.right_pad)\n",
    "            \n",
    "        else : # pad값이 안들어오면, padded된 것이라고 간주\n",
    "            self.padded_input=self.input\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.reshaped_input=self.img_batch_to_conv_stacks() # 이해하기 \n",
    "        self.batch_size=self.input.shape[0]\n",
    "        \n",
    "        reshaped_output=np.dot(self.reshaped_input,self.filter_2d)+self.b # 이해해보기\n",
    "        self.output=reshaped_output.T.reshape(self.channels_out, self.batch_size,self.output_height,self.output_width).transpose(1,0,2,3)\n",
    "        \n",
    "        return self.output\n",
    "    \n",
    "    def backward_pass(self,backprop_params):\n",
    "        alpha_adj, lam= backprop_params\n",
    "        \n",
    "        # self.output_side_deltas : ?? 어디서 나온것인지 확인하기\n",
    "        # transpose : 행렬의 axis의 이동\n",
    "        reshaped_output_side_deltas=self.output_side_deltas.transpose(1,0,2,3).reshape(self.channels_out,-1).T\n",
    "        \n",
    "        reshaped_input_side_deltas=np.dot(reshaped_output_side_deltas, self.filter_2d.T)\n",
    "        \n",
    "        self.input_side_deltas=self.conv_stack_deltas_to_input_deltas(reshaped_input_side_deltas)\n",
    "        \n",
    "        if self.pad:\n",
    "            new_bottom_index=self.input_side_deltas[2]-self.bottom_pad\n",
    "            new_right_index=self.input_side_deltas[3]-self.right_pad\n",
    "            self.input_side_deltas=self.input_side_deltas[:,:,self.top_pad:new_bottom_index,\\\n",
    "                                                         self.left_pad:new_right_index]\n",
    "            \n",
    "        self.filter_2d+=alpha_adj*np.dot(self.reshaped_input.T,reshaped_output_side_deltas)\n",
    "        self.filter_4d=self.filter_2d.T.reshape(self.shape_4d)\n",
    "        \n",
    "        self.b+=alpha_adj*self.output_side_deltas.sum(axis=(0,2,3))\n",
    "        \n",
    "        \n",
    "            \n",
    "        if lam:\n",
    "            self.filter_2d*=(1.0-lam*alpha_adj)\n",
    "            self.filter_4d*=(1.0-lam*alpha_adj)\n",
    "            \n",
    "        return self.input_side_deltas\n",
    "    \n",
    "    # input_data를 filter와 inner product할 수 있게 바꿔준다.\n",
    "    # cnn의 중요한 부분\n",
    "    def img_batch_to_conv_stacks(self):\n",
    "        \"\"\"\n",
    "        Takes the current input, a batch of images with depth, and sets the reshape_input property to be series\n",
    "        of convolutional stacks obtained by passing a square prism window with matching depth across each image\n",
    "        (left to right along the top, then next row down, etc, then same for remaining channels, then next image).\n",
    "        Each window prism is unrolled into a single 1-D row, and the stack array has dimensions\n",
    "        (batch size * number_of_windows) by (window_size^2 * depth).\n",
    "        \"\"\"\n",
    "        batch_size, img_depth, img_height,img_weight=self.padded_input.shape\n",
    "        unrolled_window_size=self.window_size**2*img_depth\n",
    "        \n",
    "        # output의 width, height 정의, depth는 filter의 개수\n",
    "        self.output_height=(img_height-self.window_size)//self.stride+1\n",
    "        self.output_width=(img_weight-self.window_size)//self.stride+1\n",
    "        \n",
    "        conv_stack=[]\n",
    "        \n",
    "        for k in range(0, batch_size): # batch끼리\n",
    "            # height기준으로, img_height-self.window_size+1 범위에서 ,stride만큼 이동 \n",
    "            for i in range(0, img_height-self.window_size+1,self.stride): \n",
    "                # weight기준으로, img_weight-self.window_size+1 범위에서 ,stride만큼 이동\n",
    "                for j in range(0, img_weight-self.window_size+1,self.stride): \n",
    "                    conv_stack.append(self.padded_input[k,:,i:i+self.window_size,j:j+self.window_size]\\\n",
    "                                     .reshape(unrolled_window_size)) # 내적을 하기 위한 전처리\n",
    "                    \n",
    "        # conv_stack shape가 어떻게 되는지 확인하기\n",
    "                    \n",
    "        return np.array(conv_stack)\n",
    "        \n",
    "    def conv_stack_deltas_to_input_deltas(self, reshaped_input_side_deltas):\n",
    "        reshaped_input_side_deltas=reshaped_input_side_deltas.reshape(self.batch_size, self.output_height, self.output_width,-1)\n",
    "        deconvolved_input_side_deltas=np.zeros(self.padded_input.shape)\n",
    "        \n",
    "        for k in range(self.batch_size):\n",
    "            for i in range(self.output_height):\n",
    "                for j in range(self.output_width):\n",
    "                    patch_to_add=reshaped_input_side_deltas[k][i][j].\\\n",
    "                    reshape(self.channels_in,self.window_size,self.window_size)\n",
    "                    \n",
    "                    in_side_i=self.stride*i\n",
    "                    in_side_j=self.stride*j\n",
    "                    deconvolved_input_side_deltas[0,0:self.channels_in,in_side_i:in_side_i+self.window_size,\\\n",
    "                                                 in_side_j:in_side_j+self.window_size]+=patch_to_add\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "        return deconvolved_input_side_deltas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
